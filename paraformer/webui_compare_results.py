#!/usr/bin/env python3
# -*- encoding: utf-8 -*-

import streamlit as st
import pandas as pd
import os
import re
import matplotlib as mpl
import plotly.graph_objects as go
import hashlib

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è¯­éŸ³è¯†åˆ«æ¨¡å‹å¯¹æ¯”åˆ†æ",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è®¾ç½®ä¸­æ–‡å­—ä½“
mpl.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial']
mpl.rcParams['axes.unicode_minus'] = False


# ä¿®æ”¹åçš„è§£æå‡½æ•°ï¼Œå¯ä»¥æ¥å—æ–‡ä»¶å¯¹è±¡æˆ–æ–‡ä»¶è·¯å¾„
def parse_results_file(file_input):
    """
    è§£ææ¨¡å‹å¯¹æ¯”ç»“æœæ–‡ä»¶ (å¯æ¥å—æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡)
    è¿”å›ï¼š
    1. æ¨¡å‹åç§°åˆ—è¡¨ (åŸºäºæ‘˜è¦ç»Ÿè®¡)
    2. æ¯ä¸ªæ–‡ä»¶çš„è¯¦ç»†ç»“æœå­—å…¸
    3. æ€»ä½“ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    content = None
    file_source_info = "æœªçŸ¥æ¥æº"  # For error messages

    # Check if input is a Streamlit UploadedFile object
    if hasattr(file_input, 'getvalue') and hasattr(file_input, 'name'):
        file_source_info = f"ä¸Šä¼ çš„æ–‡ä»¶ '{file_input.name}'"
        try:
            content_bytes = file_input.getvalue()
            content = content_bytes.decode('utf-8')
        except Exception as e:
            st.error(f"è¯»å– {file_source_info} å†…å®¹å¤±è´¥: {e}")
            return None, None, None, None
    elif isinstance(file_input, str):
        file_source_info = f"æ–‡ä»¶è·¯å¾„ '{file_input}'"
        if not os.path.exists(file_input):
            st.error(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_input}")
            return None, None, None, None
        try:
            with open(file_input, 'r', encoding='utf-8') as f:
                content = f.read()
                with open(file_input, 'rb') as fb:
                    content_bytes = fb.read()
        except Exception as e:
            st.error(f"è¯»å– {file_source_info} å¤±è´¥: {e}")
            return None, None, None, None
    else:
        st.error("æ— æ•ˆçš„æ–‡ä»¶è¾“å…¥ç±»å‹")
        return None, None, None, None

    if content is None:
        st.error(f"æ— æ³•ä» {file_source_info} è·å–å†…å®¹ã€‚")
        return None, None, None, None

    content_hash = hashlib.md5(content_bytes).hexdigest()

    parts = content.split("=== æµ‹è¯•ç»“æœç»Ÿè®¡ ===")
    if len(parts) < 2:
        st.error(f"{file_source_info} æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ç»Ÿè®¡æ‘˜è¦éƒ¨åˆ†")
        return None, None, None, content_hash

    detail_part = parts[0]
    summary_part = parts[1]

    file_results = []
    model_names_from_detail = set()

    file_pattern = r'\n\[\d+/\d+\] æ–‡ä»¶: (.+)\nå‚è€ƒæ–‡æœ¬: (.+)\nå‚è€ƒæ–‡æœ¬\(æ— æ ‡ç‚¹\): (.+)\n(.*?)-{80}'
    file_blocks = re.findall(file_pattern, detail_part, re.DOTALL)

    for file_block in file_blocks:
        file_name, ref_text, ref_text_no_punc, model_results_text = file_block
        file_result = {
            'file_name': file_name,
            'reference_text': ref_text,
            'reference_text_no_punc': ref_text_no_punc,
            'models': {}
        }

        model_pattern = r'(\S+) è¯†åˆ«ç»“æœ: (.+)\n\1 CER: ([\d.]+)%'
        model_matches = re.findall(model_pattern, model_results_text)

        for model_match in model_matches:
            model_name, rec_text, cer = model_match
            model_names_from_detail.add(model_name)
            file_result['models'][model_name] = {
                'text': rec_text,
                'cer': float(cer)
            }

        file_results.append(file_result)

    stats = {}
    total_files_match = re.search(r'æ€»æµ‹è¯•æ•°æ®æ•°é‡: (\d+)', summary_part)
    total_time_match = re.search(r'æ•´ä½“ä»»åŠ¡æ€»è€—æ—¶: ([\d.]+) ç§’', summary_part)

    if total_files_match and total_time_match:
        stats['total_files'] = int(total_files_match.group(1))
        stats['total_time'] = float(total_time_match.group(1))

    model_pattern = r'(\S+):\næˆåŠŸå¤„ç†æ•°é‡: (\d+)/\d+\nå¹³å‡å­—é”™ç‡\(CER\): ([\d.]+)%\nå¹³å‡è¯†åˆ«è€—æ—¶\(å•æ¡\): ([\d.]+)ç§’'
    model_matches = re.findall(model_pattern, summary_part)

    stats['models'] = {}
    model_names_from_summary = []
    for model_match in model_matches:
        model_name, success_count, avg_cer, avg_time = model_match
        model_name = model_name.strip(':')
        stats['models'][model_name] = {
            'success_count': int(success_count),
            'avg_cer': float(avg_cer),
            'avg_time': float(avg_time)
        }
        if model_name not in model_names_from_summary:
            model_names_from_summary.append(model_name)

    if not stats.get('models'):
        st.error(f"æœªèƒ½ä» {file_source_info} çš„æ‘˜è¦éƒ¨åˆ†è§£æå‡ºä»»ä½•æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯ã€‚")
        if model_names_from_detail:
            st.warning("å°†å°è¯•ä½¿ç”¨ä»æ–‡ä»¶è¯¦æƒ…ä¸­è§£æå‡ºçš„æ¨¡å‹åç§°ã€‚")
            return list(model_names_from_detail), file_results, stats, content_hash
        else:
            return None, None, None, content_hash

    return model_names_from_summary, file_results, stats, content_hash


# ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è¡¨æ ¼
def generate_summary_table(stats):
    """ç”Ÿæˆæ¨¡å‹æ€§èƒ½æ±‡æ€»ç»Ÿè®¡è¡¨æ ¼"""
    if not stats or 'models' not in stats:
        return None

    data = []
    for model_name, model_stats in stats['models'].items():
        data.append({
            'æ¨¡å‹åç§°': model_name,
            'æˆåŠŸè¯†åˆ«æ•°é‡': model_stats['success_count'],
            'å¹³å‡å­—é”™ç‡(CER)': f"{model_stats['avg_cer']:.2f}%",
            'å¹³å‡è¯†åˆ«è€—æ—¶(ç§’/æ¡)': f"{model_stats['avg_time']:.3f}"
        })

    return pd.DataFrame(data)


# ç”Ÿæˆæ¨¡å‹å¹³å‡CERå¯¹æ¯”æŸ±çŠ¶å›¾
def plot_model_avg_cer(stats, model_names):
    """ç”Ÿæˆæ¨¡å‹å¹³å‡CERå¯¹æ¯”æŸ±çŠ¶å›¾"""
    if not stats or 'models' not in stats or not stats['models'] or not model_names:
        st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç»Ÿè®¡æ•°æ®æ¥ç”Ÿæˆå¹³å‡CERå¯¹æ¯”å›¾ã€‚")
        return None

    models = []
    avg_cers = []

    for model_name in model_names:
        if model_name in stats['models']:
            models.append(model_name)
            avg_cers.append(stats['models'][model_name]['avg_cer'])

    if not models:
        st.warning("åœ¨ç»Ÿè®¡æ•°æ®ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆæ¨¡å‹çš„å¹³å‡CERæ•°æ®ã€‚")
        return None

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=models,
        y=avg_cers,
        text=[f"{cer:.2f}%" for cer in avg_cers],
        textposition='auto',
        marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'][:len(models)]
    ))

    fig.update_layout(
        title='æ¨¡å‹å¹³å‡å­—é”™ç‡(CER)å¯¹æ¯”',
        xaxis_title='æ¨¡å‹åç§°',
        yaxis_title='å¹³å‡å­—é”™ç‡ CER (%)',
        height=500
    )

    return fig


# ç”Ÿæˆæ¨¡å‹å¹³å‡CERå¯¹æ¯”æŠ˜çº¿å›¾
def plot_model_avg_cer_line(stats, model_names):
    """ç”Ÿæˆæ¨¡å‹å¹³å‡CERå¯¹æ¯”æŠ˜çº¿å›¾"""
    if not stats or 'models' not in stats or not stats['models'] or not model_names:
        st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç»Ÿè®¡æ•°æ®æ¥ç”Ÿæˆå¹³å‡CERæŠ˜çº¿å›¾ã€‚")
        return None

    models = []
    avg_cers = []

    for model_name in model_names:
        if model_name in stats['models']:
            models.append(model_name)
            avg_cers.append(stats['models'][model_name]['avg_cer'])

    if not models:
        st.warning("åœ¨ç»Ÿè®¡æ•°æ®ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆæ¨¡å‹çš„å¹³å‡CERæ•°æ®ã€‚")
        return None

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=models,
        y=avg_cers,
        mode='lines+markers+text',
        name='å¹³å‡CER',
        text=[f"{cer:.2f}%" for cer in avg_cers],
        textposition="top center",
        line=dict(color='royalblue', width=3),
        marker=dict(size=12)
    ))

    fig.update_layout(
        title='æ¨¡å‹å¹³å‡å­—é”™ç‡(CER)å¯¹æ¯”æŠ˜çº¿å›¾',
        xaxis_title='æ¨¡å‹åç§°',
        yaxis_title='å¹³å‡å­—é”™ç‡ CER (%)',
        height=500,
        yaxis=dict(
            range=[0, max(avg_cers) * 1.2]
        )
    )

    return fig


# ä¸»å‡½æ•°
def main():
    st.title("ğŸ¤ è¯­éŸ³è¯†åˆ«æ¨¡å‹å¯¹æ¯”åˆ†æ")

    if 'loaded_content_hash' not in st.session_state:
        st.session_state['loaded_content_hash'] = None
    if 'parsed_data' not in st.session_state:
        st.session_state['parsed_data'] = None

    with st.sidebar:
        st.header("é€‰æ‹©ç»“æœæ–‡ä»¶")

        uploaded_file = st.file_uploader(
            "ä¸Šä¼ ç»“æœæ–‡ä»¶è¿›è¡Œåˆ†æ",
            type=["txt"],
            key='result_uploader',
            help="ä¸Šä¼ æ–‡ä»¶åå°†è‡ªåŠ¨å¼€å§‹åˆ†æã€‚"
        )

        st.markdown("---")
        st.markdown("### åˆ†æè¯´æ˜")
        st.markdown("""
        æ­¤å·¥å…·ç”¨äºå¯è§†åŒ–åˆ†ææ¨¡å‹å¯¹æ¯”æµ‹è¯•ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
        - æ¨¡å‹æ€§èƒ½æ€»è§ˆï¼ˆå­—é”™ç‡ã€å¤„ç†æ—¶é—´ï¼‰
        - å¹³å‡å­—é”™ç‡å¯¹æ¯”å›¾
        """)

    if uploaded_file is not None:
        model_names, file_results, stats, current_content_hash = parse_results_file(uploaded_file)

        if current_content_hash is not None and \
           (st.session_state.loaded_content_hash != current_content_hash or st.session_state.parsed_data is None):

            st.session_state.loaded_content_hash = current_content_hash

            if model_names is not None and file_results is not None and stats is not None:
                st.session_state.parsed_data = (model_names, file_results, stats)
            else:
                st.session_state.parsed_data = None
                st.warning("æ–‡ä»¶è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹å’Œæ ¼å¼ã€‚ä¸Šæ–¹å¯èƒ½æ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯ã€‚")

        if st.session_state.parsed_data is not None:
            if st.session_state.loaded_content_hash == current_content_hash:
                model_names, file_results, stats = st.session_state.parsed_data

                if not model_names:
                    st.warning("æœªä»ç»“æœæ–‡ä»¶çš„æ‘˜è¦ä¸­è§£æå‡ºä»»ä½•æ¨¡å‹åç§°ã€‚")
                if not stats or 'models' not in stats or not stats['models']:
                    st.warning("æœªä»ç»“æœæ–‡ä»¶ä¸­è§£æå‡ºæœ‰æ•ˆçš„ç»Ÿè®¡æ‘˜è¦ã€‚")

                total_files = stats.get('total_files', 0)
                total_time = stats.get('total_time', 0)

                st.markdown(f"### æ–‡ä»¶: `{uploaded_file.name}`")
                st.markdown(f"## åŸºæœ¬ä¿¡æ¯")
                col1, col2, col3 = st.columns(3)
                col1.metric("æ€»æµ‹è¯•æ–‡ä»¶æ•°", f"{total_files}")
                col2.metric("æ€»æµ‹è¯•æ—¶é•¿", f"{total_time:.2f}ç§’")
                col3.metric("æ¨¡å‹æ•°é‡", f"{len(model_names)}")

                st.markdown("## æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
                summary_table = generate_summary_table(stats)
                if summary_table is not None and not summary_table.empty:
                    st.dataframe(summary_table, use_container_width=True)
                else:
                    st.info("æ²¡æœ‰è¶³å¤Ÿçš„ç»Ÿè®¡æ•°æ®æ¥æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½æ€»è§ˆã€‚")

                st.markdown("## æ¨¡å‹å¹³å‡å­—é”™ç‡(CER)å¯¹æ¯”")
                avg_cer_fig = plot_model_avg_cer(stats, model_names)
                if avg_cer_fig:
                    st.plotly_chart(avg_cer_fig, use_container_width=True)
                else:
                    st.info("æ— æ³•ç”Ÿæˆå¹³å‡CERæŸ±çŠ¶å›¾ã€‚")

                avg_cer_line_fig = plot_model_avg_cer_line(stats, model_names)
                if avg_cer_line_fig:
                    st.plotly_chart(avg_cer_line_fig, use_container_width=True)
                else:
                    st.info("æ— æ³•ç”Ÿæˆå¹³å‡CERæŠ˜çº¿å›¾ã€‚")

    else:
        st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼ ç»“æœæ–‡ä»¶è¿›è¡Œåˆ†æ")
        st.markdown("## æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
        st.markdown("ä¸Šä¼ æ–‡ä»¶åå°†åœ¨æ­¤å¤„æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½ç»Ÿè®¡è¡¨æ ¼å’Œå›¾è¡¨...")
        if st.session_state.parsed_data is not None:
            st.session_state.parsed_data = None
            st.session_state.loaded_content_hash = None


if __name__ == "__main__":
    main()